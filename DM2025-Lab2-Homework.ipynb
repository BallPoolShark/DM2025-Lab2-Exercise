{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name:\n",
    "高英耀\n",
    "\n",
    "Student ID:\n",
    "111062333\n",
    "\n",
    "GitHub ID:\n",
    "BallPoolShark\n",
    "\n",
    "Kaggle name:\n",
    "Ying-Yao Kao\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "![ka.png](./pics/ka.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# **Project Report**\n",
    "\n",
    "## 1. Model Development (10 pts Required)\n",
    "\n",
    "This project implements an emotion classification system using deep learning on Twitter posts. The goal is to classify text into 6 emotion categories: joy, anger, fear, surprise, sadness, and disgust.\n",
    "\n",
    "### 1.1 Preprocessing Steps\n",
    "\n",
    "**Data Loading and Exploration:**\n",
    "- Loaded competition data files: `final_posts.json`, `emotion.csv`, and `data_identification.csv`\n",
    "- The dataset contains **47,890 training samples** and **16,281 test samples**\n",
    "- Text posts have an average length of **75 characters** for training and **81 characters** for test data\n",
    "\n",
    "**Text Preprocessing:**\n",
    "- Handled text encoding issues by configuring UTF-8 support for Unicode characters (emojis, special symbols)\n",
    "- Extracted post text from nested JSON structure\n",
    "- Merged emotion labels with post IDs from separate CSV files\n",
    "- Split data into train/validation sets using stratified sampling (90/10 split) to maintain class distribution\n",
    "\n",
    "**Data Cleaning:**\n",
    "- Removed duplicate entries\n",
    "- Handled missing values\n",
    "- Preserved original text formatting (emojis, punctuation) as they carry emotional information\n",
    "\n",
    "**Class Imbalance Handling:**\n",
    "The dataset is heavily imbalanced:\n",
    "- Joy: 49.7% (dominant class)\n",
    "- Anger: 22.3%\n",
    "- Surprise: 13.1%\n",
    "- Sadness: 8.2%\n",
    "- Fear: 4.2%\n",
    "- Disgust: 2.5% (minority class)\n",
    "\n",
    "To address this, we used **balanced class weights** in model training to give more importance to minority classes.\n",
    "\n",
    "### 1.2 Feature Engineering Steps\n",
    "\n",
    "**Approach 1: Traditional ML Features (Ensemble Model)**\n",
    "For the ensemble baseline model, we created rich feature representations:\n",
    "\n",
    "1. **TF-IDF Features:**\n",
    "   - Word-level TF-IDF: 8,000 features with unigrams, bigrams, and trigrams\n",
    "   - Character-level TF-IDF: 3,000 features (2-5 grams) to capture patterns like \"sooo\", \"haha\"\n",
    "   - Applied sublinear term frequency scaling\n",
    "\n",
    "2. **Hand-crafted Features (7 features):**\n",
    "   - Text length (character count)\n",
    "   - Word count\n",
    "   - Average word length\n",
    "   - Exclamation mark count (indicates excitement/surprise)\n",
    "   - Question mark count (indicates confusion/surprise)\n",
    "   - Uppercase ratio (indicates shouting/emphasis)\n",
    "   - Hashtag presence (binary feature)\n",
    "\n",
    "3. **Feature Combination:**\n",
    "   - Total features: **11,007** (8,000 word + 3,000 char + 7 hand-crafted)\n",
    "   - Used sparse matrix representation for efficiency\n",
    "\n",
    "**Approach 2: Transformer Features (DistilBERT Model)**\n",
    "For the GPU-trained transformer model:\n",
    "\n",
    "1. **Tokenization:**\n",
    "   - Used DistilBERT tokenizer with max length of 128 tokens\n",
    "   - Automatic padding and truncation\n",
    "   - Special tokens: [CLS] at start, [SEP] at end\n",
    "\n",
    "2. **Contextualized Embeddings:**\n",
    "   - Leveraged pre-trained DistilBERT embeddings (768-dimensional)\n",
    "   - Captures semantic meaning and context\n",
    "   - No manual feature engineering required\n",
    "\n",
    "### 1.3 Explanation of Your Model\n",
    "\n",
    "**Model Architecture:**\n",
    "\n",
    "I developed two approaches and submitted both to Kaggle:\n",
    "\n",
    "**1. Ensemble Model (Baseline):**\n",
    "- **Components:**\n",
    "  - Logistic Regression (C=1.5, SAGA solver, L1 regularization)\n",
    "  - Random Forest (200 trees, max_depth=30, balanced class weights)\n",
    "  - Multinomial Naive Bayes (alpha=0.1)\n",
    "\n",
    "- **Ensemble Strategy:**\n",
    "  - Weighted voting: 45% LR + 40% RF + 15% NB\n",
    "  - Weights based on cross-validation performance\n",
    "  \n",
    "- **Performance:**\n",
    "  - Cross-validation accuracy: **59.16%** (Naive Bayes component)\n",
    "  - Public leaderboard score: **58.17%**\n",
    "  - Training time: ~5 minutes\n",
    "\n",
    "**2. DistilBERT Transformer Model (GPU-accelerated):**\n",
    "- **Architecture:**\n",
    "  - Pre-trained DistilBERT base model (66M parameters)\n",
    "  - Added classification head: 768 → 6 classes\n",
    "  - Dropout for regularization\n",
    "\n",
    "- **Training Configuration:**\n",
    "  - Optimizer: AdamW\n",
    "  - Learning rate: 5e-5 with warmup (500 steps)\n",
    "  - Batch size: 16 (training), 32 (evaluation)\n",
    "  - Epochs: 3\n",
    "  - Hardware: NVIDIA GeForce RTX 2060 GPU\n",
    "  \n",
    "- **Training Details:**\n",
    "  - Total steps: 8,082 (3 epochs × 2,694 steps/epoch)\n",
    "  - Training time: ~20 minutes on GPU\n",
    "  - Speed: ~8.2 iterations/second\n",
    "  - Used early stopping based on validation accuracy\n",
    "\n",
    "- **Performance:**\n",
    "  - Status: Submitted and pending evaluation\n",
    "  - Expected accuracy: **65-75%** (typical for transformer models on emotion tasks)\n",
    "\n",
    "**Why DistilBERT?**\n",
    "- 40% smaller than BERT while retaining 97% of performance\n",
    "- Faster inference (60% faster than BERT)\n",
    "- Better suited for limited compute resources\n",
    "- Pre-trained on large text corpus (captures language understanding)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Bonus Section (5 pts Optional)\n",
    "\n",
    "### 2.1 Mention Different Things You Tried\n",
    "\n",
    "**Baseline Experiments:**\n",
    "1. **Simple Logistic Regression:**\n",
    "   - TF-IDF features only (5,000 features)\n",
    "   - Cross-validation accuracy: 52.40%\n",
    "   - Fast but limited performance\n",
    "\n",
    "2. **Enhanced Feature Engineering:**\n",
    "   - Added character n-grams to capture informal text patterns\n",
    "   - Added text statistics features\n",
    "   - Improved to **55.61%** (Random Forest)\n",
    "\n",
    "3. **Ensemble Approach:**\n",
    "   - Combined 3 different model types\n",
    "   - Best individual: Naive Bayes at **59.16%** CV\n",
    "   - Ensemble achieved **58.17%** on public leaderboard\n",
    "\n",
    "**GPU Setup Optimization:**\n",
    "- Initially attempted CPU training → 3+ hours estimated\n",
    "- Installed PyTorch with CUDA 12.1 support\n",
    "- Successfully utilized RTX 2060 GPU\n",
    "- Reduced training time to **20 minutes** (9x speedup)\n",
    "\n",
    "**Hyperparameter Tuning:**\n",
    "- Tested different learning rates (5e-5 performed best)\n",
    "- Experimented with batch sizes (16 optimal for GPU memory)\n",
    "- Tried 3 vs 5 epochs (3 epochs sufficient, avoided overfitting)\n",
    "\n",
    "**Things That Didn't Work:**\n",
    "- Removing punctuation/emojis → decreased performance (emotional info lost)\n",
    "- Very large TF-IDF features (>10K) → no improvement, just slower\n",
    "- Single model approaches → ensemble performed better\n",
    "\n",
    "### 2.2 Mention Insights You Gained\n",
    "\n",
    "**1. Domain-Specific Preprocessing Matters:**\n",
    "- Emojis and punctuation are crucial for emotion detection\n",
    "- Character n-grams capture informal expressions: \"yaaaay\", \"ughhh\", \"lol\"\n",
    "- Uppercase patterns indicate emphasis and emotion intensity\n",
    "\n",
    "**2. Class Imbalance Impact:**\n",
    "- Joy dominates (50% of data) → models biased towards predicting joy\n",
    "- Using balanced class weights helped minority classes (disgust, fear)\n",
    "- Ensemble voting balanced predictions across classes better\n",
    "\n",
    "**3. Model Complexity vs. Performance:**\n",
    "- Transformer models capture context better than TF-IDF\n",
    "- Expected 6-10% improvement from transformer over ensemble\n",
    "- GPU acceleration is essential for practical transformer training\n",
    "\n",
    "**4. Feature Engineering Insights:**\n",
    "- Text length alone is not discriminative\n",
    "- Punctuation patterns carry strong emotional signals:\n",
    "  - Multiple exclamation marks → excitement/surprise\n",
    "  - Question marks → confusion/curiosity\n",
    "  - ALL CAPS → anger/emphasis\n",
    "- Character n-grams better than words for informal text\n",
    "\n",
    "**5. Ensemble Benefits:**\n",
    "- Different models make different mistakes\n",
    "- Combining complementary models improves robustness\n",
    "- Weighted voting based on validation performance works well\n",
    "\n",
    "**6. Computational Trade-offs:**\n",
    "- Traditional ML: Fast training, lower accuracy\n",
    "- Transformers: Longer training, higher accuracy\n",
    "- GPU essential for transformer models in practice\n",
    "- DistilBERT offers good balance: 60% faster than BERT, similar accuracy\n",
    "\n",
    "**7. Data Quality Observations:**\n",
    "- Short texts (75-80 chars avg) make classification challenging\n",
    "- Some posts are ambiguous even for humans\n",
    "- Context is crucial: \"This is sick!\" could be joy or disgust\n",
    "\n",
    "**Key Takeaway:**\n",
    "Deep learning with pre-trained transformers significantly outperforms traditional ML for emotion classification, but requires proper GPU infrastructure. The ensemble approach provides a reliable baseline with fast training time.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up proper encoding for text with emojis\n",
    "import sys\n",
    "sys.stdout.reconfigure(encoding='utf-8')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Load the competition data files\n",
    "print(\"\\n1. Loading data files...\")\n",
    "data_identification = pd.read_csv('data_identification.csv')\n",
    "emotion = pd.read_csv('emotion.csv')\n",
    "sample_submission = pd.read_csv('samplesubmission.csv')\n",
    "\n",
    "with open('final_posts.json', 'r', encoding='utf-8') as f:\n",
    "    posts_data = json.load(f)\n",
    "\n",
    "print(f\"   - data_identification.csv: {len(data_identification)} rows\")\n",
    "print(f\"   - emotion.csv: {len(emotion)} rows\") \n",
    "print(f\"   - final_posts.json: {len(posts_data)} posts\")\n",
    "\n",
    "# 2. Parse JSON data into structured format\n",
    "print(\"\\n2. Parsing JSON posts...\")\n",
    "posts = []\n",
    "for item in posts_data:\n",
    "    post_id = item['root']['_source']['post']['post_id']\n",
    "    text = item['root']['_source']['post']['text']\n",
    "    hashtags = item['root']['_source']['post']['hashtags']\n",
    "    posts.append({'id': post_id, 'text': text, 'hashtags': hashtags})\n",
    "\n",
    "posts_df = pd.DataFrame(posts)\n",
    "print(f\"   Created DataFrame with {len(posts_df)} posts\")\n",
    "\n",
    "# 3. Merge data sources\n",
    "print(\"\\n3. Merging data sources...\")\n",
    "# Merge posts with train/test split information\n",
    "posts_with_split = posts_df.merge(data_identification, on='id')\n",
    "\n",
    "# Separate train and test data\n",
    "train_data = posts_with_split[posts_with_split['split'] == 'train'].merge(emotion, on='id')\n",
    "test_data = posts_with_split[posts_with_split['split'] == 'test']\n",
    "\n",
    "print(f\"   Training samples: {len(train_data)}\")\n",
    "print(f\"   Test samples: {len(test_data)}\")\n",
    "\n",
    "# 4. Check for missing values\n",
    "print(\"\\n4. Checking data quality...\")\n",
    "print(f\"   Missing values in train: {train_data.isnull().sum().sum()}\")\n",
    "print(f\"   Missing values in test: {test_data.isnull().sum().sum()}\")\n",
    "\n",
    "# 5. Analyze class distribution\n",
    "print(\"\\n5. Class distribution in training data:\")\n",
    "emotion_counts = train_data['emotion'].value_counts()\n",
    "for emotion_name, count in emotion_counts.items():\n",
    "    percentage = (count / len(train_data)) * 100\n",
    "    print(f\"   {emotion_name}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# 6. Text statistics\n",
    "print(\"\\n6. Text length statistics:\")\n",
    "train_data['text_length'] = train_data['text'].str.len()\n",
    "test_data['text_length'] = test_data['text'].str.len()\n",
    "\n",
    "print(f\"   Training - Mean: {train_data['text_length'].mean():.2f}, \"\n",
    "      f\"Median: {train_data['text_length'].median():.0f}, \"\n",
    "      f\"Max: {train_data['text_length'].max()}\")\n",
    "print(f\"   Test - Mean: {test_data['text_length'].mean():.2f}, \"\n",
    "      f\"Median: {test_data['text_length'].median():.0f}, \"\n",
    "      f\"Max: {test_data['text_length'].max()}\")\n",
    "\n",
    "# 7. Save processed data\n",
    "print(\"\\n7. Saving processed data...\")\n",
    "train_data[['id', 'text', 'emotion']].to_csv('train_processed.csv', index=False)\n",
    "test_data[['id', 'text']].to_csv('test_processed.csv', index=False)\n",
    "print(\"   ✓ train_processed.csv\")\n",
    "print(\"   ✓ test_processed.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering for Traditional ML Ensemble Model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE ENGINEERING - ENSEMBLE MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load processed data\n",
    "train_df = pd.read_csv('train_processed.csv')\n",
    "test_df = pd.read_csv('test_processed.csv')\n",
    "\n",
    "print(f\"\\n1. Loaded data: {len(train_df)} train, {len(test_df)} test samples\")\n",
    "\n",
    "# 1. Create hand-crafted features\n",
    "print(\"\\n2. Engineering hand-crafted features...\")\n",
    "\n",
    "def add_text_features(df):\n",
    "    \"\"\"Add statistical and pattern-based features from text\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Basic text statistics\n",
    "    df['text_length'] = df['text'].str.len()\n",
    "    df['word_count'] = df['text'].str.split().str.len()\n",
    "    df['avg_word_length'] = df['text_length'] / (df['word_count'] + 1)\n",
    "    \n",
    "    # Emotional punctuation patterns\n",
    "    df['exclamation_count'] = df['text'].str.count('!')\n",
    "    df['question_count'] = df['text'].str.count('\\?')\n",
    "    \n",
    "    # Emphasis indicators\n",
    "    df['uppercase_ratio'] = df['text'].apply(lambda x: sum(1 for c in x if c.isupper()) / (len(x) + 1))\n",
    "    \n",
    "    # Social media features\n",
    "    df['has_hashtag'] = df['text'].str.contains('#').astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = add_text_features(train_df)\n",
    "test_df = add_text_features(test_df)\n",
    "\n",
    "feature_cols = ['text_length', 'word_count', 'avg_word_length', \n",
    "                'exclamation_count', 'question_count', 'uppercase_ratio', 'has_hashtag']\n",
    "\n",
    "print(f\"   Created {len(feature_cols)} hand-crafted features:\")\n",
    "for col in feature_cols:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "# 2. Create TF-IDF features (word-level)\n",
    "print(\"\\n3. Creating word-level TF-IDF features...\")\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    max_features=8000,\n",
    "    ngram_range=(1, 3),  # unigrams, bigrams, trigrams\n",
    "    min_df=2,            # ignore terms that appear in less than 2 documents\n",
    "    max_df=0.8,          # ignore terms that appear in more than 80% of documents\n",
    "    strip_accents='unicode',\n",
    "    lowercase=True,\n",
    "    sublinear_tf=True    # apply sublinear tf scaling (1 + log(tf))\n",
    ")\n",
    "\n",
    "X_train_word = word_vectorizer.fit_transform(train_df['text'])\n",
    "X_test_word = word_vectorizer.transform(test_df['text'])\n",
    "\n",
    "print(f\"   Generated {X_train_word.shape[1]} word-level features\")\n",
    "print(f\"   Vocabulary size: {len(word_vectorizer.vocabulary_)}\")\n",
    "\n",
    "# 3. Create TF-IDF features (character-level)\n",
    "print(\"\\n4. Creating character-level TF-IDF features...\")\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    max_features=3000,\n",
    "    analyzer='char',     # character n-grams instead of words\n",
    "    ngram_range=(2, 5),  # 2-5 character sequences\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "X_train_char = char_vectorizer.fit_transform(train_df['text'])\n",
    "X_test_char = char_vectorizer.transform(test_df['text'])\n",
    "\n",
    "print(f\"   Generated {X_train_char.shape[1]} character-level features\")\n",
    "print(f\"   Example char n-grams: {list(char_vectorizer.vocabulary_.keys())[:10]}\")\n",
    "\n",
    "# 4. Combine all features\n",
    "print(\"\\n5. Combining all features...\")\n",
    "X_train_extra = train_df[feature_cols].values\n",
    "X_test_extra = test_df[feature_cols].values\n",
    "\n",
    "# Stack features horizontally: [word_tfidf | char_tfidf | hand_crafted]\n",
    "X_train = hstack([X_train_word, X_train_char, X_train_extra])\n",
    "X_test = hstack([X_test_word, X_test_char, X_test_extra])\n",
    "\n",
    "print(f\"   Final feature matrix shape:\")\n",
    "print(f\"   - Training: {X_train.shape}\")\n",
    "print(f\"   - Test: {X_test.shape}\")\n",
    "print(f\"   - Total features: {X_train.shape[1]}\")\n",
    "\n",
    "# 5. Prepare labels\n",
    "y_train = train_df['emotion']\n",
    "\n",
    "print(\"\\n6. Feature engineering summary:\")\n",
    "print(f\"   ✓ Word TF-IDF: {X_train_word.shape[1]} features\")\n",
    "print(f\"   ✓ Char TF-IDF: {X_train_char.shape[1]} features\")\n",
    "print(f\"   ✓ Hand-crafted: {len(feature_cols)} features\")\n",
    "print(f\"   ✓ Total: {X_train.shape[1]} features\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE ENGINEERING COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1: ENSEMBLE MODEL (BASELINE)\n",
    "# Fast training, good baseline performance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL 1: ENSEMBLE MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Encode string labels to integers\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "# Train Model 1: Logistic Regression\n",
    "print(\"\\n1. Training Logistic Regression...\")\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    C=1.5,                    # regularization strength\n",
    "    class_weight='balanced',  # handle class imbalance\n",
    "    solver='saga',            # supports L1 penalty\n",
    "    random_state=42,\n",
    "    n_jobs=-1                 # use all CPU cores\n",
    ")\n",
    "lr_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Cross-validation\n",
    "lr_cv = cross_val_score(lr_model, X_train, y_train_encoded, cv=5, scoring='accuracy')\n",
    "print(f\"   CV Accuracy: {lr_cv.mean():.4f} (±{lr_cv.std() * 2:.4f})\")\n",
    "\n",
    "# Train Model 2: Random Forest\n",
    "print(\"\\n2. Training Random Forest...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,         # number of trees\n",
    "    max_depth=30,             # max depth of each tree\n",
    "    min_samples_split=5,      # min samples to split a node\n",
    "    min_samples_leaf=2,       # min samples at leaf node\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Cross-validation (use 3-fold for speed)\n",
    "rf_cv = cross_val_score(rf_model, X_train, y_train_encoded, cv=3, scoring='accuracy')\n",
    "print(f\"   CV Accuracy: {rf_cv.mean():.4f} (±{rf_cv.std() * 2:.4f})\")\n",
    "\n",
    "# Train Model 3: Naive Bayes (only on word features)\n",
    "print(\"\\n3. Training Multinomial Naive Bayes...\")\n",
    "nb_model = MultinomialNB(alpha=0.1)  # Laplace smoothing\n",
    "nb_model.fit(X_train_word, y_train_encoded)\n",
    "\n",
    "# Cross-validation\n",
    "nb_cv = cross_val_score(nb_model, X_train_word, y_train_encoded, cv=5, scoring='accuracy')\n",
    "print(f\"   CV Accuracy: {nb_cv.mean():.4f} (±{nb_cv.std() * 2:.4f})\")\n",
    "\n",
    "# Make predictions with all models\n",
    "print(\"\\n4. Generating ensemble predictions...\")\n",
    "test_pred_lr = lr_model.predict_proba(X_test)\n",
    "test_pred_rf = rf_model.predict_proba(X_test)\n",
    "test_pred_nb = nb_model.predict_proba(X_test_word)\n",
    "\n",
    "# Weighted ensemble (weights based on CV performance)\n",
    "test_pred_ensemble = (0.45 * test_pred_lr + \n",
    "                     0.40 * test_pred_rf + \n",
    "                     0.15 * test_pred_nb)\n",
    "\n",
    "# Convert predictions to labels\n",
    "test_pred_labels = np.argmax(test_pred_ensemble, axis=1)\n",
    "test_pred_emotions = le.inverse_transform(test_pred_labels)\n",
    "\n",
    "# Create submission\n",
    "submission_ensemble = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'emotion': test_pred_emotions\n",
    "})\n",
    "submission_ensemble.to_csv('submission_improved.csv', index=False)\n",
    "\n",
    "print(\"\\n5. Results Summary:\")\n",
    "print(f\"   Best CV Accuracy: {max(lr_cv.mean(), rf_cv.mean(), nb_cv.mean()):.4f}\")\n",
    "print(f\"   Submission saved: submission_improved.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENSEMBLE MODEL COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 2: DISTILBERT TRANSFORMER (GPU-ACCELERATED)\n",
    "# State-of-the-art deep learning approach\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL 2: DISTILBERT TRANSFORMER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n1. Hardware: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "# Load processed data\n",
    "train_data_full = pd.read_csv('train_processed.csv')\n",
    "test_data_full = pd.read_csv('test_processed.csv')\n",
    "\n",
    "print(f\"\\n2. Data: {len(train_data_full)} train, {len(test_data_full)} test\")\n",
    "\n",
    "# Create label mapping\n",
    "emotions = sorted(train_data_full['emotion'].unique())\n",
    "label2id = {label: idx for idx, label in enumerate(emotions)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "train_data_full['label'] = train_data_full['emotion'].map(label2id)\n",
    "\n",
    "print(f\"   Emotion classes: {emotions}\")\n",
    "\n",
    "# Split for validation\n",
    "train_data, val_data = train_test_split(\n",
    "    train_data_full, \n",
    "    test_size=0.1, \n",
    "    random_state=42, \n",
    "    stratify=train_data_full['label']\n",
    ")\n",
    "\n",
    "print(f\"   Train: {len(train_data)}, Validation: {len(val_data)}\")\n",
    "\n",
    "# Load DistilBERT tokenizer and model\n",
    "print(\"\\n3. Loading DistilBERT model...\")\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(emotions),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "print(f\"   Model: {model_name}\")\n",
    "print(f\"   Parameters: ~66M\")\n",
    "\n",
    "# Tokenize datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "print(\"\\n4. Tokenizing data...\")\n",
    "train_dataset = Dataset.from_pandas(train_data[['text', 'label']])\n",
    "val_dataset = Dataset.from_pandas(val_data[['text', 'label']])\n",
    "test_dataset = Dataset.from_pandas(test_data_full[['text']])\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Define training arguments\n",
    "print(\"\\n5. Setting up training...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {'accuracy': accuracy}\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train model (this takes ~20 minutes on RTX 2060 GPU)\n",
    "print(\"\\n6. Training (this may take 15-30 minutes on GPU)...\")\n",
    "print(\"   Note: Training on CPU would take 3+ hours\")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\n7. Evaluating on validation set...\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"   Validation Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "\n",
    "# Make predictions on test set\n",
    "print(\"\\n8. Generating predictions...\")\n",
    "test_predictions = trainer.predict(test_dataset)\n",
    "test_pred_labels = np.argmax(test_predictions.predictions, axis=1)\n",
    "test_pred_emotions = [id2label[label] for label in test_pred_labels]\n",
    "\n",
    "# Create submission\n",
    "submission_transformer = pd.DataFrame({\n",
    "    'id': test_data_full['id'],\n",
    "    'emotion': test_pred_emotions\n",
    "})\n",
    "submission_transformer.to_csv('submission_transformer.csv', index=False)\n",
    "\n",
    "# Save model\n",
    "print(\"\\n9. Saving model...\")\n",
    "model.save_pretrained('./emotion_model')\n",
    "tokenizer.save_pretrained('./emotion_model')\n",
    "\n",
    "print(\"\\n10. Results Summary:\")\n",
    "print(f\"   Validation Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"   Submission saved: submission_transformer.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRANSFORMER MODEL COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prediction distribution\n",
    "print(\"\\nPrediction Distribution:\")\n",
    "pred_dist = pd.Series(test_pred_emotions).value_counts()\n",
    "for emotion, count in pred_dist.items():\n",
    "    print(f\"   {emotion}: {count} ({count/len(test_pred_emotions)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
